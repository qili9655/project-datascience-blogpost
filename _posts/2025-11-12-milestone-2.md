---
layout: post
title: "Milestone 2"
date: 2025-11-12
---

<br>
<br>

# Introduction
L'objectif pour ce milestone est de créer des modèles prédictifs de la probabilité que les tirs aboutissent en buts, ou les *expected Goals, xG*, selon diverses caractéristiques telles la position du tir, le type de tir, la situation de l'équipe au moment du tirs, etc.
Nous démontrerons la démarche pour développer 5 modèles de prédiction, et notre ingénierie des caractéristiques pour inclure plus de facteurs pertinents dans la prédiction des *xG*.
L'entraînement de tous les modèles a été effectué avec les données de la saison 2016/17 à 2019/20.
Modèles prédictifs (enregistrés sur la plateforme WandB)
- Classifieur de régression logistique avec la distance
- Classifieur de régression logistique avec l'angle
- Classifieur de régression logistique avec la distance et l'angle
- XGBoost
- ADABoost
<br>

# Partie 2: Ingénierie des caractéristiques simples
## Relation des tirs/buts selon leur distance et angle par rapport au filet
Nous commençons d'abord par explorer la relation entre quelques caractéristiques de base potentiellement importantes pour la prédiction des *xG* et le nombre de tirs et de buts.<br>
Voici 3 figures visualisant le nombre de tirs et de buts selon les caractéristiques:<br>
- Distances par rapport au filet
- Angle du tir
- Distance par rapport au *et* angle du tir

![Hist_tirs_ distance](/figures/Hist_tirs_distance.png)
![Hist_tir_angle](/figures/Hist_tirs_angle.png)
![Hist_tirs_distance_angle](/figures/Hist_tirs_distance_angle.png)
<br>
Le premier histogramme révèle une relation très forte entre la distance au filet et la fréquence des tirs ainsi que des buts. Le nombre de tirs augmente en se rapprochant du filet et atteint un maximum autour de 5 à 10 pieds, et décroît avec la distance. La proportion de buts suit la même tendance : les tirs effectués très près du filet génèrent beaucoup plus de buts que ceux provenant de zones plus éloignées. Cette association est logique : plus un joueur est proche du filet, plus la probabilité de marquer augmente.

À l’inverse, la relation entre l’angle du tir et la fréquence des tirs est beaucoup moins marquée. On observe davantage de tirs à des angles très ouverts (0–10 degrés) ainsi qu’entre 20 et 45 degrés, probablement en raison de la géométrie des zones offensives et du positionnement typique des attaquants. Les buts se produisent majoritairement avec des tirs à moins de 40 degrés par rapport au but, tandis que les tirs à des angles plus extrêmes (>50–60°) génèrent très peu de buts. Toutefois, le lien entre l’angle et le nombre de buts reste faible. Ceci démontre que l’angle joue un rôle, mais qu’il est beaucoup moins déterminant que la distance. 

Enfin, la heatmap renforce ces observations. La majorité des tirs se concentrent dans une zone logique : proches du filet (0–50 pieds) et angles modérés (<50 degrés). Une petite densité autour de 60 pieds et 30 degrés apparaît, mais elle est vraisemblablement attribuable à du bruit ou un artefact de binning, puisqu’il n’existe pas de justification tactique ou mécanique pour une concentration réelle de tirs à cet endroit. Dans l’ensemble, la distribution bidimensionnelle confirme que la distance est le facteur dominant dans la génération d’occasions dangereuses, tandis que l’angle est un modulateur secondaire.
<br>
<br>

Ensuite, nous avions validé davantage nos données en examinant s'il y avait des buts provenant d'endroits impossible
<mark>produire 1 histogramme de buts uniquement (y), classés par distance (x), et séparez les événements nets vides et
non vides<mark>
![Taux_but_distance](/figures/Taux_but_distance.png)
-	Coordonnées xy impossibles
-	Mauvais types de tirs

# Partie 3 : Modèles de base
## Modèle de régression logistique
Pour commencer le développement de modèles prédictifs, nous avons entraîné un modèle de base: le classifieur `LogisticRegression()`, avec seulement la distance comme paramètre du modèle. La précision de ce classifieur est de 0.091, donc seulement 9.1 % des tirs prédits comme « but » étaient vraiment des buts. <br>
En examinant les prédictions produites par ce modèle, on observe rapidement les limites d'utiliser seulement la précision. La précision est définie comme le rapport entre le nombre de vrais buts correctement prédits et l’ensemble des tirs que le modèle identifie comme buts. Par contre, dans les données en hockey, les classes sont très débalancées, c'est-à-dire que le nombre total de buts est extrêmement faible par rapport au nombre total de tirs. Dans ce contexte, même un modèle performant du point de vue de la capacité de classement des tirs aura tendance à prédire très peu d’événements comme « but », ce qui entraînera toujours une précision faible. La précision dépend beaucoup de la prévalence de l'événement à prédire (buts) en plus de la performance du modèle, et si cet événement est rare, elle restera faible peu importe le modèle. <br>
Par conséquent, la précision (ainsi que le *accuracy*) n’est pas une bonne métrique dans notre contexte de classes débalancées pour évaluer la performance des modèles. Elle est utile dans des contextes où on veut éviter des faux positifs, ce qui n'est pas l'objectif de nos modèles de *xG*. Il faut donc utiliser d’autres métriques mieux adaptées aux données déséquilibrées, notamment l’AUC, les courbes de calibration, le taux de buts par centile ou encore la proportion cumulée de buts capturés.

En tenant en compte les limitations d'un seul modèle et d'une seule métrique de performance, nous avons entraîné 2 autres classificateurs `LogisticRegression()` (un modèle avec l'angle du tir comme paramètre et un autre modèle avec la distance *et* l'angle comme paramètres) et avons inclus davantage de métriques. 

Pour chaque modèle, voici une description de sa performance  et 4 graphiques démontrant les métriques de performance suivantes:
- Courbe de ROC et la métrique AUC
- Taux de buts en fonction du centile de probabilité du tir selon le modèle
- Proportion cumulée de buts en fonction du centile de probabilité selon le modèle
- Diagramme de fiabilité

## Classifieur `LogisticRegression` entraîné avec *la distance* 
![Métriques_LR_dist](/figures/Métriques_LR_dist.png)

Valeurs des métriques de performances:
```
model_distance/accuracy:   0.976623197586826
model_distance/auc:        0.7487254246038493
model_distance/f1:         0.13894016176125112
model_distance/precision:  0.09128996692392503
model_distance/recall:     0.2906486941870261
```
- La courbe ROC est bien au-dessus de la diagonale du classificateur aléatoire et l'AUC ~ 0.75, indiquant une bonne performance de classement pour un modèle simple. Plus on se déplace vers le coin supérieur gauche, plus cela confirme que la distance est une information très utile.
- Lorsqu'on trie les tirs selon la probabilité prédite (courbe du taux de buts par centile), on observe que les centiles des probabilités les plus élevées (100-90%) contiennent un taux de buts de ~17%, beaucoup plus qu'aux taux moyens. Le modèle réussit donc à classer les tirs les plus dangereux dans les centiles plus élevés. La courbe des taux de buts diminuent graduellement vers les centiles plus bas, ce qu'on s'attend d'une courbe d'un modèle qui a un bon pouvoir de classement. 
- La courbe de proportion cumulée de buts monte rapidement : les centiles les plus élevés capturent rapidement une grande proportion des buts. Ainsi, une petite fraction des tirs “hautement dangereux" récupère rapidement une large part des buts. Cela appuie davantage que la bonne performance du modèle. 
- La courbe de calibration permet de vérifier si les probabilités prédites par le modèle correspondent aux probabilités réelles observées.
Dans ce graphique, la ligne bleue du modèle est presque confondue avec la diagonale noire (ligne idéale). Elle est tout légèrement sous la diagonale, donc sous-estime légèrement la probabilité réelle des buts. Cela signifie que lorsque le modèle prédit, par exemple, une probabilité de 10 % de marquer, on observe effectivement environ 10% de buts dans ces cas-là. Le modèle est bien calibré, il ne surestime ni ne sous-estime de manière notable les chances de marquer. Toutefois, on remarque que toutes les valeurs sont concentrées en dessous de 0,2, ce qui montre que le modèle attribue généralement de très faibles probabilités de but à l’ensemble des tirs. En résumé, la calibration est bonne, mais la discrimination reste faible.
<br>
<br>

## Classifieur `LogisticRegression` entraîné avec *l'angle*
![Métriques_LR_angle](/figures/Métriques_LR_angle.png)
Valeurs des métriques de performances:
```
model_angle/accuracy:      0.976623197586826
model_angle/auc:           0.6322638528771083
model_angle/f1:            0.07299311439177128
model_angle/precision:     0.04059249921210211
model_angle/recall:        0.3616961527660769
```
- LA courbe ROC est presque collée à la diagonale en pointillé noir, ce qui indique que le modèle ne parvient pas à bien distinguer les tirs qui se terminent par un but de ceux qui ne marquent pas. Autrement dit, la probabilité qu’il attribue à chaque tir est souvent trop proche du hasard. L’angle seul apporte donc très peu d’information discriminante comparé à la distance : deux tirs ayant des angles différents ne sont pas systématiquement associés à des probabilités de but très différentes. La forme quasi linéaire de la courbe montre que le modèle n’apprend qu’un signal extrêmement faible, ce qui se reflète dans une AUC très basse (~0.63) et très proche d’un classifieur aléatoire.
- On observe que les taux de buts sont faibles (max 9% comparé à 17-18% pour les 2 autres modèles) et presque constants d’un centile à l’autre, sans augmentation nette vers les centiles élevés. La courbe a également une plus grande variabilité comparée aux autres modèles (re-augmente au centile 20), ce qui ne concorde pas avec les attentes d'un modèle de bonne performance. Cela signifie que le modèle ne parvient pas à ordonner correctement les tirs selon leur risque réel. Les tirs classés parmi les 10 % les plus probables ne présentent qu’une légère augmentation du taux de but. 
- La courbe orange suit une forme presque linéaire, sans forte courbure vers le haut. Cela signifie que le modèle ne parvient pas à concentrer les buts dans les centiles les plus probables. En d’autres termes, les buts sont répartis de manière presque uniforme sur l’ensemble des tirs, au lieu d’être regroupés dans les tirs à haute probabilité. Ce comportement correspond à ce que l’on attend d’un modèle peu performant : même si l’ordre des tirs est influencé par l’angle, cet ordre ne correspond pas réellement à la qualité des occasions de marquer. À l’inverse, un modèle performant afficherait une courbe très convexe (un faible pourcentage de tirs regroupe la majorité des buts).
- La courbe bleue est quasiment confondue avec la diagonale, ce qui signifie que les probabilités prédites sont globalement bien calibrées. Cependant, comme la majorité des probabilités sont très faibles (0.0–0.1), le modèle reste bien calibré mais peu discriminant. Il prédit juste, mais il prédit surtout des valeurs très faibles pour presque tous les tirs. Cette apparence de calibration est donc moins une preuve de qualité qu’une conséquence du manque d’information contenue dans l’angle seul : le modèle prédit toujours des valeurs faibles et reste dans une zone "sécuritaire" où il est difficile de mal calibrer ses prédictions. 

## Classifieur `LogisticRegression` entraîné avec *la distance et l'angle*
![Métriques_LR_angle](/figures/Métriques_LR_dist_angle.png)
Valeurs des métriques de performances:
```
model_distanceangle/accuracy:   0.976623197586826
model_distanceangle/auc:        0.8098626300211255
model_distanceangle/f1:         0.1617653193175656
model_distanceangle/precision:  0.11506735505311258
model_distanceangle/recall:     0.2722549845549003
```

- La courbe ROC est nettement au-dessus de la diagonale, ce qui indique une bonne capacité du modèle à distinguer les tirs qui deviennent des buts de ceux qui ne le deviennent pas. Le modèle présente donc une meilleure séparation que les modèles basés sur une seule variable (distance ou angle seul). En pratique, cela signifie que le modèle attribue des probabilités plus élevées aux tirs réellement dangereux. L’intégration de la distance et de l’angle améliore la discrimination des tirs réussis vs non-réussis, car ces deux caractéristiques capturent des aspects complémentaires de la dangerosité d’un tir : proximité du filet et angle de tir plus central. La meilleure performance du modèle se reflète dans une valeur d'AUC supérieure et une courbe davantage recourbée vers le coin supérieur gauche.
- On observe une forte décroissance du taux de buts entre les centiles les plus élevés et les plus faibles. Les tirs classés parmi les 10 % les plus probables ont un taux de buts d’environ 17 %, tandis que les plus faibles se situent autour de 2 %. Cela montre que le modèle classe correctement les tirs selon leur dangerosité : plus la probabilité prédite est grande, plus le tir a réellement de chances de se transformer en but. Par rapport aux modèles utilisant uniquement la distance ou uniquement l’angle, la pente est ici plus marquée, ce qui indique une meilleure séparation entre tirs dangereux et non dangereux. Cette courbe confirme que l’ajout de l’angle renforce la pertinence du classement produit par le modèle. 
- La courbe monte rapidement : en ne conservant qu’une petite portion des tirs les mieux classés, on capture déjà la majorité des buts. Par exemple, environ 40 % des tirs prédits comme les plus “dangereux” contiennent près de 80 % des buts. Ce résultat confirme que le modèle identifie efficacement les occasions à haut risque et qu’il est utile pour évaluer la qualité des tirs. La combinaison distance + angle produit ici une courbe plus convexe que les modèles à une seule variable, ce qui montre une capacité accrue à concentrer les buts dans les centiles les plus élevés. 
- La courbe bleue est très proche de la diagonale idéale, ce qui signifie que les probabilités prédites reflètent fidèlement les probabilités réelles observées. Autrement dit, si le modèle prédit 20 % de chances de marquer, on observe environ 20 % de buts dans ces cas. Le modèle est donc bien calibré, en plus d’être performant. 


# Partie 4 : Ingénierie des caractéristiques avancées
Afin d'optimiser la performance de nos modèles, nous avons ajouté ajouté plus de caractéristiques à nos dataframes et effectué des ingénieries de caractéristiques dans le but d'entraîner nos modèles avec davantage de paramètres et des paramètres plus pertinents. <br>
<br>
Voici une liste exhaustive de toutes les caractéristiques que nous comptons utiliser, répertoriés avec leur nom dans le dataframe des données d'entraînement.
<br>
<mark> Caractéristiques non incluses dans df_clean:<br>
- prev_xCoord
- prev_yCoord
- delta_t <br>
mais requises par le devoir:
- Coordonnées du dernier événement (x, y, colonnes séparées)
- Temps écoulé depuis le dernier événement (secondes) <mark>

```python
df_clean = df[[
        # Coordonnées
        "xCoord", "yCoord",
        # Géométrie
        "distance_net", "angle_net",
        # Target et empty net
        "is_goal", "empty_net",
        # Temps
        "game_seconds", "game_period",
        # Type de tir
        "shot_type",
        # Features dérivées
        "is_rebound", "change_in_angle", "shot_speed", "distance_prev_event",
        # Métadonnées
        "season", "teamAbbr", "idGame",
        # Contexte
        "prev_event", "prev_team"
    ]].copy()
```
<mark>Liste de toutes les caractéristiques créées et description simple des nouvelles caractéristiques
- Nouvelles caractéristiques power-play :
    - Le temps écoulé depuis le début du jeu de puissance (secondes) 
    - Nombre de patineurs non-gardiens amicaux sur la glace
    - Nombre de patineurs non-gardiens adverses sur la glace<mark>


## Liste de caractéristiques 

| nom_de_colonne        | Description                                                                                  |
|-----------------------|------------------------------------------------------------------------------------------------------------------------|
| `season`                | Saison NHL de l’événement (ex. 2019, 2020…).                                                                           |
| `teamAbbr`              | Abréviation de l’équipe du tireur (ex. MTL, TOR).                                                                     |
| `idGame`                | Identifiant unique du match.                                                                                           |
| `xCoord`                | Coordonnée X de l’emplacement du tir sur la patinoire.                                                                |
| `yCoord`                | Coordonnée Y de l’emplacement du tir sur la patinoire.                                                                |
| `distance_net`          | Distance (en pieds) entre le tireur et le centre du filet au moment du tir.                                           |
| `angle_net`             | Angle du tir par rapport au centre du filet (en degrés).                                                               |
| `is_goal`               | Variable cible : 1 si le tir est un but, 0 sinon.                                                                     |
| `empty_net`             | 1 si le but est marqué dans un filet désert, 0 sinon (actuellement toujours 0 si non renseigné dans les données).     |
| `game_seconds`          | Nombre de secondes écoulées depuis le début du match (périodes incluses).                                             |
| `game_period`           | Période de jeu actuelle (1, 2, 3 ou prolongation).                                                                    |
| `shot_type`             | Type de tir (ex. wrist, snap, slap, tip-in).                                                                          |
| `prev_event`            | Type de l’événement immédiatement précédent (ex. shot-on-goal, goal, pass…).                                          |
| `prev_team`             | Abréviation de l’équipe ayant effectué l’événement précédent.                                                         |
| `prev_xCoord`         | Coordonnée X de l’événement immédiatement précédent dans le même match (tir, passe, récupération, etc.).                   |
| `prev_yCoord`         | Coordonnée Y de l’événement immédiatement précédent dans le même match.                                                      |
| `prev_time`           | Temps du dernier événement dans la période, en format "MM:SS".                                                               |
| `time_sec`            | Temps du tir converti en secondes depuis le début de la période (par ex. "03:42" → 222 secondes).                           |
| `prev_time_sec`       | Temps de l’événement précédent converti en secondes depuis le début de la période.                                           |
| `delta_t`             | Différence en secondes entre l’événement précédent et le tir actuel (time_sec - prev_time_sec).                             |
| `distance_prev_event`   | Distance (en pieds) entre l’événement précédent et le tir actuel.                                                     |
| `prev_angle_net`      | Angle du dernier tir par rapport au filet (existe uniquement si l’événement précédent était un tir ou un but).              |
| `is_rebound`            | 1 si l’événement précédent du même match était un tir (rebond), 0 sinon.                                              |
| `change_in_angle`       | Changement d’angle entre le tir précédent et le tir actuel (0 si pas un rebond).                                      |
| `shot_speed`            | « Vitesse » approximative avant le tir, définie comme distance_prev_event / delta_t.                                   |

## Exemple de dataframe 
Comme exemple, nous avons produit un dataframe pour le match Winnipeg vs Washington du 12 mars 2018 avec les caractéristiques ci-hautes. <br>
Voici le lien URL menant à l'expérience (*run*) stockant l'artéfact du dataframe:<br>
https://wandb.ai/qi-li-1-universit-de-montr-al/IFT6758-2025/runs/43tifjuy?nw=nwuserqili1

# Partie 5 : XGBoost
Pour explorer des modèles prédictifs plus avancés, nous avons créé différentes version du modèle XGBoost. 
<br>

Pour entraîner et évaluer ces modèles, nous avons utilisé les fonctions `generate_train_val_test_datasets()` (`feature_ingenering.py`) et `load_and_prepare_data()` (`model_xgboost.py`), qui chargent les données des saisons 2016/17 à 2019/20 pour constituer les ensembles d’entraînement et de validation (80%, soit 193 227 tirs, en entraînement, et 20%, soit 48 307 tirs en validation), et réservent complètement la saison 2020/21 (57 734 tirs) comme ensemble de test indépendant. Les variables catégorielles (notamment `shot_type`) sont automatiquement encodées en one-hot, les valeurs manquantes sont gérées, et les sorties consistent en des matrices prêtes pour la modélisation. Comme attendu en hockey, la proportion de buts demeure faible (~9–10 %), créant un déséquilibre marqué (≈ 1 but pour 9,6 tirs non convertis), contexte qui peut favoriser un biais des modèles vers la classe majoritaire. <br>
Voici un aperçu de la distribution des tirs et des buts dans les 3 ensembles données:

![Distribution_train_val_test](/figures/Distribution_train_val_test.png)
<br>
<br>

## Classifieur XGBoost entraîné avec *la distance par rapport au filet et l'angle du tir*
Nous avons fait un premier essai simple du XGBoost avec les caractéristiques simples de la partie 3, c'est-à-dire la distance du tir par rapport au filet et l'angle du tir. Voici les courbes contenant les mêmes métriques de performance que le classifieur simple de `LogisticRegression()`: 

![Métriques_XGB_Baseline](/figures/Métriques_XGB_Baseline.png)

Le modèle simple de régression logistique a obtenu des performances plus solides que celle du XGBoost, atteignant une AUC de 0.81, avec une sensibilité notablement plus élevée (rappel ≈ 0.27). XGBoost génère une AUC d’environ 0.70 et demeure moins performant sur toutes les métriques liées aux buts, notamment en rappel et en calibration. Cette différence suggère que, avec une faible dimension de caractéristiques (seulement 2: distance, angle), la régression logistique capture plus efficacement la structure quasi-linéaire de la relation entre position du tir et probabilité de but, tandis que XGBoost, sans ajustement du déséquilibre (ex. *scale_pos_weight*), a davantage tendance à se rabattre sur la classe majoritaire. 
<br>

XGBoost a une fonction qui nous donne l'importance des caractéristiques selon:<br>
- L'amélioration de la fonction de perte que chaque caractéristique amène dans la tâche de classification
- Le nombre d'échantillons impacté par cette caractéristique
- Le nombre de fois que cette caractéristique a été utilisées dans la tâche <br>
Elle nous informe donc sur la contribution de chaque caractéristique à mieux classer les entrées. En utilisant cette fonction (`model.feature_importance_`) sur les deux caractéristiques ci-haut, nous obtenons la même conclusion que dans la partie 3, c'est-à-dire que la distance est une caractéristique beaucoup plus importante que l'angle.

![Importance_feat_baseline](/figures/Importance_feat_baseline.png)


## Classifieur XGBoost entraîné avec *toutes les caractéristiques de la partie 4*
Par la suite, pour optimiser notre XGBoost, nous avons utilisé la totalité des 18 caractéristiques créées dans la partie 4. Avec la fonction ous avons également effectué une recherche de la meilleure combinaison d'hyperparamètres parmi la liste ci-dessous par la méthode `RandomizedSearch`. Cette approche présente plusieurs avantages comparée au `GridSearchCV`: elle explore un espace d’hyperparamètres potentiellement très large sans tester toutes les combinaisons possible, réduisant le coût computationnel. De plus, elle permet d’échantillonner aléatoirement des configurations diverses et souvent plus efficaces, améliorant les chances de découvrir une bonne région de l’espace de recherche. Elle est donc bien adaptée aux modèles complexes comme XGBoost, où l’espace d’hyperparamètres peut être très vaste.
<br>

Liste d'hyperparamètres recherchés: 
```python
param_grid = {
    'max_depth': [3, 5, 7],  # Profondeur maximale des arbres (contrôle la complexité: 3=simple, 7=complexe)
    'learning_rate': [0.01, 0.05, 0.1],  # Taux d'apprentissage (*shrinkage*)
    'n_estimators': [100, 200, 300],  # Nombre d'arbres (*boosting iterations*)
    'min_child_weight': [1, 3, 5],  # Régularisation: poids minimum d'une feuille
    'subsample': [0.8, 0.9, 1.0],  # % d'échantillons par arbre
    'colsample_bytree': [0.8, 0.9, 1.0],  # % de features par arbre
    'scale_pos_weight': [scale_pos_weight, scale_pos_weight*0.5]  # Poids de la classe positive (pour gérer le déséquilibre)
}
```

Ceci donne l'espace de recherche avec les caractéristiques suivantes: <br>
- Combinaisons totales recherchées: 1,458
- Méthode: RandomizedSearchCV (100 essais)
- Validation croisée: 5-fold
- Métrique d'optimisation: ROC AUC
<br>

En entraînant le nouveau modèle avec la stratégie de recherche ci-dessus, nous obtenons la meilleure combinaison ci-dessous:<br>
- max_depth: 5
- learning_rate: 0.05
- n_estimators: 200
- subsample: 0.9
- n_estimators: 200
- subsample: 0.9
- colsample_bytree: 0.8
- min_child_weight: 3
- scale_pos_weight: 4.779426229508197
- colsample_bytree: 0.8
- min_child_weight: 3
- scale_pos_weight: 4.779426229508197
<br>

Et une amélioration des métriques de performance: <br>
| Métrique de performance       | Valeur                                                                                  |
|-----------------------|------------------------------------------------------------------------------------------------------------------------|
| AUC-ROC            | 0.7518                                                                           |
| Accuracy           | 0.8248                                                                         |
| Precision          | 0.2390                                                                         |
| Recall           | 0.3891                                                                         |
| F1-Score           | 0.2961                                                                         |


Amelioration vs Baseline:<br>
AUC:    +5.35%  (OK)<br>
Recall: 0.0033 -> 0.3891  (delta: +0.3858, le modele detecte maintenant ~119x plus de buts!)
<br>
<br>
Voici quelques figures démontrant l'effet des ajustements d'hyperparamètres sur la performance du modèle:
![Parallel_coord_plot](/figures/roc_curves_analysis.png)
![Hyperparameter_importance](/figures/roc_curves_analysis.png)
![Scatterplot_CV_AUC_vs_hyperparameters](/figures/roc_curves_analysis.png)
<br>
<br>

Finalement, nous avons généré des courbes des 4 métriques de performance du modèle avec la meilleure combinaison d'hyperparamètres. Ces courbes seront affichées à la fin de cette section, avec l'ensemble des courbes des modèles XGBoost qui seront générés. 
<br>
<br>

## Classifieur XGBoost entraîné avec des *caractéristiques sélectionnées*
Pour réduire la complexité du modèle et sélectionner les caractéristiques les plus pertinentes, nous avons utilisé la fonction de **`Feature Importance`** de XGBoost, une méthode rapide et directement interprétable qui mesure la contribution de chaque variable aux décisions des arbres (nombre de splits, gain d’information, qualité de séparation). Voici les 10 caractéristiques les plus importantes selon cette fonction:<br>

![top_ten_feat_by_importance](/figures/top_ten_feat_by_importance.png)

Voici les métriques de performance d'un modèle XGBoost entraîné avec les 10 caractéristiques ci-dessus et la meilleure combinaison d'hyperparamètres trouvés à la section précédente:<br>
| Métrique de performance       | Valeur                                                                                  |
|-----------------------|------------------------------------------------------------------------------------------------------------------------|
| AUC-ROC            | 0.7478                                                                           |
| Accuracy           | 0.9054                                                                         |
| Precision          | 0.5660                                                                     |
| Recall           | 0.0066                                                                         |
| F1-Score           | 0.0130                                                                    |
<br>

Cette approche a permis d’isoler naturellement les dimensions les plus déterminantes du modèle, notamment la géométrie du tir (distance_net, angle_net, xCoord, yCoord), certains types de tirs (wrist, slap, snap, etc.) ainsi que des éléments de contexte temporel et de jeu comme game_seconds ou is_rebound. La réduction finale à environ dix caractéristiques offre un excellent compromis : un modèle plus simple (≈44% de variables en moins), plus rapide, robuste (moins de risque de *overfitting*) et inteprétable, tout en conservant plus de 99% de la performance AUC du modèle complet. Cette réduction peut engendrer une très légère baisse de performance (~0.006 AUC), mais élimine surtout des caractéristiques redondantes, peu informatives ou bruitées, ce qui améliore la lisibilité et la stabilité globale du modèle. <br>


## Courbes de métriques de performance: ensemble des modèles XGBoost
Pour conclure la section, voici les 4 courbes de tous les modèles XGBoost générés ci-haut.
![ROC_curves_analyis](/figures/roc_curves_analysis.png)
![xgboost_cumulative_goals](/figures/xgboost_cumulative_goals.png)
![xgboost_goal_rate_percentile](/figures/xgboost_goal_rate_percentile.png)
![xgboost_calibration_curves](/figures/xgboost_calibration_curves.png)


<mark> Autres stratégies de sélection de caractéristiques?<mark>
-	parcimonie, encapsulage, filtering, SHAP

# Question 6 : Nouveau modèle
Tentatives et discuter de chaque technique:
-	ADABoost
-	Réseau de neurone 
-	Division plus réfléchie des données d’entraînement :
o	entraîner sur une saison et valider sur une autre saison
o	enlever 20 premiers matchs de la saison 
4 graphiques de la meilleure technique :
![Courbe ROC et AUC pour meilleure technique + ligne aléatoire]
![Taux de but en fonction du centile pour meilleure technique + ligne aléatoire]
![Taux de but cumulé en fonction du centile pour meilleure technique + ligne aléatoire]
![diagramme de fiabilité pour meilleure technique + ligne aléatoire]

# Question 7 :
TrainVal + test
4 figures à inclure
![Courbe ROC et AUC pour 5 modèles 2019-2020 + ligne aléatoire]
![Taux de but en fonction du centile pour 5 modèles 2019-2020 + ligne aléatoire]
![Taux de but cumulé en fonction du centile pour 5 modèles 2019-2020 + ligne aléatoire]
![diagramme de fiabilité pour 5 modèles 2019-2020 + ligne aléatoire]
-	Testez vos 5 modèles sur l'ensemble de données intact de la saison régulière 2019/20. Discutez de vos résultats et de vos observations sur l'ensemble de données test. Vos modèles fonctionnent-ils aussi bien sur l'ensemble de test que sur votre ensemble de validation lors de la construction de vos modèles? Certains modèles fonctionnent-ils mieux ou moins bien que prévu?
![Courbe ROC et AUC pour 5 modèles séries bruts + ligne aléatoire]
![Taux de but en fonction du centile pour 5 modèles séries bruts + ligne aléatoire]
![Taux de but cumulé en fonction du centile pour 5 modèles séries bruts + ligne aléatoire]
![diagramme de fiabilité pour 5 modèles séries bruts + ligne aléatoire]
-	Testez vos 5 modèles sur les matchs des séries éliminatoires. Discutez de vos résultats et de vos observations sur cet ensemble de tests. Y a-t-il des différences par rapport à l'ensemble de tests de la saison régulière ou obtenez-vous des performances de « généralisation » similaires?


# Modèle enregistrés dans le répertoire Wandb
-	Logistic Regression distance
-	Logistic Regression angle
-	Logistic Regression distance + angle
-	XGBoost
-	Meilleur Modèle
